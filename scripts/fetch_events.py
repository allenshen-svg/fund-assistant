#!/usr/bin/env python3
"""
åŸºé‡‘åŠ©æ‰‹ - å®è§‚äº‹ä»¶è‡ªåŠ¨è¿½è¸ªç®¡é“
GitHub Actions æ¯2å°æ—¶è¿è¡Œ: æŠ“å–è´¢ç»æ–°é—» â†’ LLMç»“æ„åŒ–æå– â†’ è¾“å‡º data/hot_events.json

æ•°æ®æµ: æ–°é—»æº â†’ AIäº‹ä»¶æç‚¼ â†’ æ¦‚å¿µæ ‡ç­¾ â†’ è¡Œä¸šæ˜ å°„ â†’ hot_events.json â†’ å‰ç«¯æ¶ˆè´¹
"""

import json, os, re, sys, ssl, time
from datetime import datetime, timezone, timedelta
from urllib.request import urlopen, Request

# ==================== é…ç½® ====================
API_KEY = os.environ.get('AI_API_KEY', '')
API_BASE = os.environ.get('AI_API_BASE', 'https://api.302.ai/v1')
MODEL = os.environ.get('AI_MODEL', 'deepseek-ai/DeepSeek-V3')
OUTPUT_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'hot_events.json')

# 20ä¸ªæ ¸å¿ƒå¸‚åœºæ ‡ç­¾ (å‰ç«¯fundæ ‡ç­¾ä½“ç³»å¯¹é½)
MARKET_TAGS = [
    'äººå·¥æ™ºèƒ½', 'AIç®—åŠ›', 'åŠå¯¼ä½“', 'æœºå™¨äºº', 'å¤§æ¨¡å‹',
    'æ–°èƒ½æº', 'å…‰ä¼', 'é”‚ç”µ', 'æ–°èƒ½æºè½¦',
    'ç™½é…’', 'æ¶ˆè´¹', 'åŒ»è¯', 'æ¸¯è‚¡ç§‘æŠ€',
    'é»„é‡‘', 'æœ‰è‰²é‡‘å±', 'åŸæ²¹', 'å†›å·¥',
    'çº¢åˆ©', 'å€ºåˆ¸', 'å®½åŸº',
]

# æ ‡ç­¾ â†’ è¡Œä¸šæ¿å—æ˜ å°„ (ä¸å‰ç«¯ FUND_SECTOR_KEYWORD_MAP å¯¹é½)
TAG_TO_SECTORS = {
    'äººå·¥æ™ºèƒ½': ['AI/ç§‘æŠ€', 'ç§‘æŠ€', 'AIGC'],
    'AIç®—åŠ›': ['AI/ç§‘æŠ€', 'åŠå¯¼ä½“', 'ç®—åŠ›'],
    'åŠå¯¼ä½“': ['åŠå¯¼ä½“', 'èŠ¯ç‰‡', 'ç§‘æŠ€'],
    'æœºå™¨äºº': ['æœºå™¨äºº', 'AI/ç§‘æŠ€', 'ç§‘æŠ€'],
    'å¤§æ¨¡å‹': ['AI/ç§‘æŠ€', 'AIGC', 'ç§‘æŠ€'],
    'æ–°èƒ½æº': ['æ–°èƒ½æº', 'å…‰ä¼', 'é”‚ç”µ'],
    'å…‰ä¼': ['å…‰ä¼', 'æ–°èƒ½æº'],
    'é”‚ç”µ': ['é”‚ç”µ', 'æ–°èƒ½æº', 'ç”µæ± '],
    'æ–°èƒ½æºè½¦': ['æ–°èƒ½æºè½¦', 'æ–°èƒ½æº'],
    'ç™½é…’': ['ç™½é…’', 'æ¶ˆè´¹', 'é£Ÿå“é¥®æ–™'],
    'æ¶ˆè´¹': ['æ¶ˆè´¹', 'é£Ÿå“é¥®æ–™', 'å†…éœ€'],
    'åŒ»è¯': ['åŒ»è¯', 'åˆ›æ–°è¯', 'ç”Ÿç‰©åŒ»è¯'],
    'æ¸¯è‚¡ç§‘æŠ€': ['æ¸¯è‚¡ç§‘æŠ€', 'æ¸¯è‚¡äº’è”ç½‘', 'æ’ç”Ÿç§‘æŠ€', 'QDIIç§‘æŠ€'],
    'é»„é‡‘': ['é»„é‡‘', 'è´µé‡‘å±'],
    'æœ‰è‰²é‡‘å±': ['æœ‰è‰²é‡‘å±', 'é“œé“', 'å¤§å®—å•†å“'],
    'åŸæ²¹': ['åŸæ²¹', 'èƒ½æº', 'æ²¹æ°”'],
    'å†›å·¥': ['å†›å·¥', 'å›½é˜²', 'èˆªå¤©'],
    'çº¢åˆ©': ['çº¢åˆ©', 'é«˜è‚¡æ¯', 'ä½æ³¢åŠ¨'],
    'å€ºåˆ¸': ['å€ºåˆ¸', 'å›ºæ”¶', 'çº¯å€º'],
    'å®½åŸº': ['å®½åŸº', 'æ²ªæ·±300', 'ä¸­è¯500'],
}

CATEGORY_ICONS = {
    'technology': 'ğŸ¤–', 'geopolitics': 'ğŸŒ', 'monetary': 'ğŸ¦',
    'policy': 'ğŸ“œ', 'commodity': 'ğŸ›¢ï¸', 'market': 'ğŸ“Š',
}


def _ssl_ctx():
    ctx = ssl.create_default_context()
    ctx.check_hostname = False
    ctx.verify_mode = ssl.CERT_NONE
    return ctx


def fetch_http(url, timeout=15):
    """GET request with timeout and error handling"""
    req = Request(url, headers={
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) fund-assistant/2.0',
        'Accept': 'application/json, text/xml, */*',
    })
    try:
        with urlopen(req, timeout=timeout, context=_ssl_ctx()) as resp:
            return resp.read().decode('utf-8', errors='replace')
    except Exception as e:
        print(f"  [WARN] fetch failed: {url[:80]}... - {e}", file=sys.stderr)
        return None


# ==================== æ–°é—»æºæŠ“å– ====================

def fetch_sina_news():
    """æ–°æµªè´¢ç»æ»šåŠ¨å¿«è®¯ (é«˜ä¿¡å™ªæ¯”, ä¸­æ–‡)"""
    items = []
    raw = fetch_http('https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2516&k=&num=40&page=1')
    if not raw:
        return items
    try:
        data = json.loads(raw)
        for item in (data.get('result', {}).get('data', []) or []):
            title = (item.get('title') or '').strip()
            if title and len(title) > 8:
                items.append({'title': title, 'source': 'æ–°æµªè´¢ç»', 'time': item.get('ctime', '')})
    except Exception as e:
        print(f"  [WARN] sina parse: {e}", file=sys.stderr)
    return items


def fetch_eastmoney_news():
    """ä¸œæ–¹è´¢å¯Œ7Ã—24å¿«è®¯ (é«˜ä¿¡å™ªæ¯”, ä¸­æ–‡)"""
    items = []
    raw = fetch_http('https://np-listapi.eastmoney.com/comm/web/getNewsByColumns?type=0&client=web&maxNewsId=0&pageSize=40&column=102')
    if not raw:
        return items
    try:
        data = json.loads(raw)
        for item in (data.get('data', {}).get('list', []) or []):
            title = (item.get('title') or '').strip()
            content = (item.get('content') or '').strip()
            text = title or content[:100]
            if text and len(text) > 6:
                items.append({'title': text, 'source': 'ä¸œæ–¹è´¢å¯Œ', 'time': item.get('showTime', '')})
    except Exception as e:
        print(f"  [WARN] eastmoney parse: {e}", file=sys.stderr)
    return items


def fetch_cls_news():
    """è´¢è”ç¤¾å¿«è®¯ (ç”µæŠ¥, æœºæ„çº§ä¿¡å™ªæ¯”)"""
    items = []
    raw = fetch_http('https://www.cls.cn/nodeapi/updateTelegraphList?app=CailianpressWeb&os=web&sv=8.4.6&rn=30')
    if not raw:
        return items
    try:
        data = json.loads(raw)
        for item in (data.get('data', {}).get('roll_data', []) or []):
            title = (item.get('title') or item.get('content', '')[:100]).strip()
            title = re.sub(r'<[^>]+>', '', title)  # strip HTML
            if title and len(title) > 6:
                ctime = item.get('ctime', 0)
                time_str = datetime.fromtimestamp(ctime, tz=timezone(timedelta(hours=8))).isoformat() if ctime else ''
                items.append({'title': title, 'source': 'è´¢è”ç¤¾', 'time': time_str})
    except Exception as e:
        print(f"  [WARN] cls parse: {e}", file=sys.stderr)
    return items


def fetch_rss_bbc():
    """BBC Business RSS (å›½é™…è§†è§’)"""
    import xml.etree.ElementTree as ET
    items = []
    raw = fetch_http('https://feeds.bbci.co.uk/news/business/rss.xml')
    if not raw:
        return items
    try:
        root = ET.fromstring(raw)
        for item in root.findall('.//item')[:15]:
            title = (item.findtext('title') or '').strip()
            if title:
                items.append({'title': title, 'source': 'BBC', 'time': item.findtext('pubDate', '')})
    except Exception as e:
        print(f"  [WARN] BBC RSS: {e}", file=sys.stderr)
    return items


# ==================== LLM ç»“æ„åŒ–æå– ====================

def call_llm(news_items):
    """è°ƒç”¨å¤§æ¨¡å‹å°†æ–°é—»åˆ—è¡¨ â†’ ç»“æ„åŒ–äº‹ä»¶ + çƒ­åº¦æ ‡ç­¾"""
    if not API_KEY:
        print("[ERROR] AI_API_KEY not set, cannot call LLM", file=sys.stderr)
        return None

    # æ„å»ºæ–°é—»æ–‡æœ¬ (å»é‡, é™åˆ¶é•¿åº¦)
    seen = set()
    unique = []
    for n in news_items:
        key = re.sub(r'\W', '', n['title'])[:30]
        if key not in seen:
            seen.add(key)
            unique.append(n)
    news_text = '\n'.join([
        f"{i+1}. [{n['source']}] {n['title']}"
        for i, n in enumerate(unique[:50])
    ])

    tags_str = 'ã€'.join(MARKET_TAGS)

    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªé¡¶çº§é‡åŒ–é‡‘èåˆ†æå¸ˆï¼Œæ“…é•¿ä»è´¢ç»æ–°é—»ä¸­æå–æŠ•èµ„ä¿¡å·ã€‚

## ä»»åŠ¡ä¸€ï¼šæå–é«˜å½±å“åŠ›æ”¿ç»äº‹ä»¶
ä»æ–°é—»ä¸­**ä»…æå–æ”¿æ²»ã€ç»æµã€é‡‘èæ”¿ç­–ã€åœ°ç¼˜æ”¿æ²»ã€å¤®è¡Œè´§å¸æ”¿ç­–ã€è´¢æ”¿æ”¿ç­–ã€è´¸æ˜“æ”¿ç­–ã€äº§ä¸šæ”¿ç­–ã€å¤§å®—å•†å“ä¾›éœ€å˜åŒ–**ç­‰æ”¿ç»ç±»äº‹ä»¶ã€‚
ä¸¥æ ¼è¿‡æ»¤æ‰ä»¥ä¸‹æ— å…³å†…å®¹ï¼šå¨±ä¹å…«å¦ã€ä½“è‚²èµ›äº‹ã€ç¤¾ä¼šæ–°é—»ã€å¤©æ°”ã€ç”Ÿæ´»æ–¹å¼ã€æ˜æ˜Ÿã€ç»¼è‰ºç­‰ã€‚
æå–å½±å“åŠ›â‰¥3æ˜Ÿ(æ»¡5æ˜Ÿ)çš„é‡å¤§æ”¿ç»äº‹ä»¶ï¼Œåˆå¹¶åŒç±»æ–°é—»ã€‚
æ¯ä¸ªäº‹ä»¶å¿…é¡»æ ‡æ³¨å½±å“çš„è¡Œä¸šæ¿å—(æ­£é¢/è´Ÿé¢)ã€‚æœ€å¤šè¾“å‡º12æ¡äº‹ä»¶ã€‚

**é‡è¦ï¼šç¡®ä¿äº‹ä»¶è¦†ç›–å°½å¯èƒ½å¤šçš„è¡Œä¸šæ¿å—ã€‚** é™¤äº†AI/ç§‘æŠ€ã€å€ºåˆ¸ç­‰çƒ­é—¨æ¿å—ä»¥å¤–ï¼Œå¿…é¡»ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹æ¿å—çš„ç›¸å…³æ–°é—»å¹¶æå–äº‹ä»¶ï¼š
- **å¤§å®—å•†å“**: åŸæ²¹/æ²¹æ°”ä»·æ ¼å˜åŠ¨ã€OPECå†³ç­–ã€é“œé“ç­‰æœ‰è‰²é‡‘å±æ¶¨è·Œã€é»„é‡‘ç™½é“¶èµ°åŠ¿
- **èƒ½æºä¸èµ„æº**: èƒ½æºæ”¿ç­–ã€çŸ¿äº§èµ„æºä¾›éœ€ã€ç¢³æ’æ”¾æ”¿ç­–
- **æ¶ˆè´¹ä¸å†…éœ€**: ç¤¾é›¶æ•°æ®ã€æ¶ˆè´¹æ”¿ç­–ã€ç™½é…’/é£Ÿå“è¡Œä¸šåŠ¨æ€
- **åŒ»è¯å¥åº·**: åŒ»è¯æ”¿ç­–ã€é›†é‡‡ã€åˆ›æ–°è¯å®¡æ‰¹
- **å†›å·¥å›½é˜²**: å†›è´¹é¢„ç®—ã€è£…å¤‡é‡‡è´­ã€åœ°ç¼˜å†²çª
å¦‚æœæ–°é—»ä¸­æœ‰æ¶‰åŠæœ‰è‰²é‡‘å±(é“œã€é“ã€é”Œã€ç¨€åœŸç­‰)ã€åŸæ²¹/æ²¹æ°”ã€é»„é‡‘ç™½é“¶ç­‰å¤§å®—å•†å“çš„å†…å®¹ï¼ŒåŠ¡å¿…å•ç‹¬æå–ä¸ºäº‹ä»¶ã€‚

sectors_positive å’Œ sectors_negative å­—æ®µåº”ä½¿ç”¨ä»¥ä¸‹æ ‡å‡†æ¿å—åï¼š
AI/ç§‘æŠ€ã€åŠå¯¼ä½“ã€ç®—åŠ›ã€AIGCã€æ–°èƒ½æºã€å…‰ä¼ã€é”‚ç”µã€æ–°èƒ½æºè½¦ã€æ¶ˆè´¹ã€é£Ÿå“é¥®æ–™ã€ç™½é…’ã€åŒ»è¯ã€åˆ›æ–°è¯ã€
é»„é‡‘ã€è´µé‡‘å±ã€æœ‰è‰²é‡‘å±ã€é“œé“ã€å¤§å®—å•†å“ã€èƒ½æºã€åŸæ²¹ã€æ²¹æ°”ã€
å†›å·¥ã€å›½é˜²ã€çº¢åˆ©ã€é«˜è‚¡æ¯ã€å€ºåˆ¸ã€å›ºæ”¶ã€é‡‘èã€é“¶è¡Œã€åˆ¸å•†ã€
æ¸¯è‚¡ç§‘æŠ€ã€æ¸¯è‚¡äº’è”ç½‘ã€æ’ç”Ÿç§‘æŠ€ã€åœ°äº§ã€åŸºå»ºã€å®½åŸº

fund_keywords å­—æ®µåº”åŒ…å«èƒ½åŒ¹é…åˆ°åŸºé‡‘åç§°/ç±»å‹çš„å…³é”®è¯ï¼Œå¦‚: äººå·¥æ™ºèƒ½ã€AIã€ç®—åŠ›ã€é»„é‡‘ã€æœ‰è‰²é‡‘å±ã€æ²¹æ°”ã€åŸæ²¹ã€æ–°èƒ½æºã€åŠå¯¼ä½“ã€å†›å·¥ã€æ¶ˆè´¹ã€åŒ»è¯ã€çº¢åˆ©ç­‰ã€‚

## ä»»åŠ¡äºŒï¼šç”Ÿæˆå¸‚åœºæ ‡ç­¾çƒ­åº¦
åŸºäºæ‰€æœ‰æ–°é—»çš„ç»¼åˆè¯­ä¹‰åˆ†æï¼Œä¸ºä»¥ä¸‹21ä¸ªå¸‚åœºæ ‡ç­¾è¯„ä¼°çƒ­åº¦å’Œæƒ…ç»ªï¼š
{tags_str}
- temperature: 0-100ï¼Œåæ˜ å½“å‰å¸‚åœºå…³æ³¨åº¦ (50=æ­£å¸¸, 80+=é«˜çƒ­, 20-=å†°å†·)
- sentiment: -1åˆ°+1ï¼Œåæ˜ åˆ©å¥½/åˆ©ç©ºæ–¹å‘

## ä¸¥æ ¼è¾“å‡ºæ ¼å¼ (çº¯JSONï¼Œä¸è¦markdown/æ³¨é‡Š/å¤šä½™æ–‡å­—)ï¼š
{{
  "events": [
    {{
      "title": "ä¸€å¥è¯äº‹ä»¶æ‘˜è¦(15å­—å†…)",
      "category": "technology|geopolitics|monetary|policy|commodity|market",
      "concepts": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
      "sentiment": 0.8,
      "impact": 4,
      "sectors_positive": ["AI/ç§‘æŠ€", "åŠå¯¼ä½“"],
      "sectors_negative": [],
      "fund_keywords": ["äººå·¥æ™ºèƒ½", "AI", "ç®—åŠ›"],
      "reason": "30å­—å†…ç®€æ",
      "advice": "15å­—å†…æ“ä½œå»ºè®®"
    }}
  ],
  "heatmap": [
    {{ "tag": "äººå·¥æ™ºèƒ½", "temperature": 85, "sentiment": 0.8 }}
  ],
  "outlook_summary": "50å­—å†…å¸‚åœºæ€»è§ˆ"
}}"""

    payload = json.dumps({
        "model": MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¯·åˆ†æä»¥ä¸‹{len(unique)}æ¡æœ€æ–°æ–°é—»ï¼Œåªæå–æ”¿æ²»ç»æµé‡‘èç›¸å…³äº‹ä»¶ï¼Œå¿½ç•¥å¨±ä¹ä½“è‚²ç¤¾ä¼šç­‰æ— å…³æ–°é—»ï¼š\n\n{news_text}"}
        ],
        "temperature": 0.2,
        "max_tokens": 4096,
    })

    req = Request(
        f"{API_BASE}/chat/completions",
        data=payload.encode('utf-8'),
        headers={
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {API_KEY}',
        }
    )

    try:
        with urlopen(req, timeout=90, context=_ssl_ctx()) as resp:
            result = json.loads(resp.read().decode('utf-8'))
            content = result['choices'][0]['message']['content']
            # strip markdown code fences
            content = re.sub(r'```json\s*', '', content)
            content = re.sub(r'```\s*', '', content)
            return json.loads(content.strip())
    except Exception as e:
        print(f"[ERROR] LLM call failed: {e}", file=sys.stderr)
        return None


# ==================== æ•°æ®ç»„è£… ====================

def load_previous():
    """åŠ è½½ä¸Šæ¬¡æ•°æ®, ç”¨äºè®¡ç®—è¶‹åŠ¿"""
    try:
        with open(OUTPUT_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return None


def compute_trend(current_temp, prev_data, tag):
    """å¯¹æ¯”ä¸Šæ¬¡æ¸©åº¦, åˆ¤æ–­è¶‹åŠ¿æ–¹å‘"""
    if not prev_data or 'heatmap' not in prev_data:
        return 'stable'
    prev = next((h for h in prev_data['heatmap'] if h['tag'] == tag), None)
    if not prev:
        return 'new'
    diff = current_temp - prev.get('temperature', 50)
    if diff > 5:
        return 'up'
    if diff < -5:
        return 'down'
    return 'stable'


def enrich_event(evt, idx, now):
    """è¡¥å…¨äº‹ä»¶å­—æ®µ, è®¡ç®—impact/confidence, ç”Ÿæˆid"""
    # ä»conceptsæ¨å¯¼ sectors_positive/negative (å¦‚æœLLMæ²¡è¿”å›)
    if not evt.get('sectors_positive'):
        sectors = []
        for concept in evt.get('concepts', []):
            sectors.extend(TAG_TO_SECTORS.get(concept, []))
        evt['sectors_positive'] = list(dict.fromkeys(sectors))[:5]  # dedup

    if 'sectors_negative' not in evt:
        evt['sectors_negative'] = []

    # è®¡ç®— confidence (sentimentå¼ºåº¦ + impactçº§åˆ«)
    sentiment = evt.get('sentiment', 0)
    impact_level = evt.get('impact', 3)
    confidence = min(1.0, max(0.3, abs(sentiment) * 0.5 + impact_level * 0.12))

    # å°† impact_level (1-5) æ˜ å°„åˆ°å®é™… impact å€¼ (-20 to +20)
    impact_value = int(sentiment * impact_level * 4)
    impact_value = max(-20, min(20, impact_value))

    return {
        "id": f"evt_{now.strftime('%Y%m%d')}_{idx+1:03d}",
        "title": evt.get('title', ''),
        "category": evt.get('category', 'market'),
        "concepts": evt.get('concepts', []),
        "sentiment": round(sentiment, 2),
        "impact": impact_value,
        "confidence": round(confidence, 2),
        "sectors_positive": evt.get('sectors_positive', []),
        "sectors_negative": evt.get('sectors_negative', []),
        "fund_keywords": evt.get('fund_keywords', []),
        "reason": evt.get('reason', ''),
        "advice": evt.get('advice', ''),
        "source": "AIç»¼åˆåˆ†æ",
        "time": now.isoformat(),
    }


# å¤§å®—å•†å“/èµ„æºå¸¸é©»äº‹ä»¶æ¨¡æ¿ (LLMæœªè¦†ç›–æ—¶è‡ªåŠ¨æ³¨å…¥)
_COMMODITY_FALLBACKS = [
    {
        "key_sectors": {'é»„é‡‘', 'è´µé‡‘å±'},
        "template": {
            "title": "é¿é™©èµ„äº§å—é’ç",
            "category": "commodity",
            "concepts": ["é»„é‡‘"],
            "sentiment": 0.3,
            "impact": 3,
            "sectors_positive": ["é»„é‡‘", "è´µé‡‘å±", "æœ‰è‰²é‡‘å±"],
            "sectors_negative": [],
            "fund_keywords": ["é»„é‡‘", "è´µé‡‘å±", "é¿é™©", "ç™½é“¶", "æœ‰è‰²é‡‘å±"],
            "reason": "åœ°ç¼˜ä¸ç¡®å®šæ€§+å¤®è¡Œè´­é‡‘ï¼Œé»„é‡‘ä½œä¸ºé¿é™©èµ„äº§ç»´æŒå…³æ³¨",
            "advice": "é»„é‡‘ETFä½œåº•ä»“é…ç½®",
        },
    },
    {
        "key_sectors": {'æœ‰è‰²é‡‘å±', 'é“œé“', 'å¤§å®—å•†å“'},
        "template": {
            "title": "å…¨çƒæœ‰è‰²é‡‘å±éœ€æ±‚æ—ºç››",
            "category": "commodity",
            "concepts": ["æœ‰è‰²é‡‘å±"],
            "sentiment": 0.3,
            "impact": 3,
            "sectors_positive": ["æœ‰è‰²é‡‘å±", "é“œé“", "å¤§å®—å•†å“", "èµ„æº"],
            "sectors_negative": [],
            "fund_keywords": ["æœ‰è‰²é‡‘å±", "é“œ", "é“", "èµ„æº", "çŸ¿ä¸š"],
            "reason": "æ–°åŸºå»º+æ–°èƒ½æºè½¦å¸¦åŠ¨é“œé“éœ€æ±‚ï¼Œæœ‰è‰²é‡‘å±ç»´æŒç»“æ„æ€§è¡Œæƒ…",
            "advice": "æœ‰è‰²é‡‘å±ETFæ³¢æ®µæ“ä½œ",
        },
    },
    {
        "key_sectors": {'èƒ½æº', 'åŸæ²¹', 'æ²¹æ°”'},
        "template": {
            "title": "å›½é™…æ²¹ä»·æ³¢åŠ¨åŠ å‰§",
            "category": "commodity",
            "concepts": ["åŸæ²¹"],
            "sentiment": 0.1,
            "impact": 2,
            "sectors_positive": ["èƒ½æº", "åŸæ²¹", "æ²¹æ°”", "å¤§å®—å•†å“"],
            "sectors_negative": [],
            "fund_keywords": ["åŸæ²¹", "æ²¹æ°”", "çŸ³æ²¹", "å¤©ç„¶æ°”", "èƒ½æº"],
            "reason": "OPECå‡äº§é¢„æœŸ+åœ°ç¼˜å†²çªï¼Œæ²¹æ°”ä»·æ ¼æ³¢åŠ¨ä¿¡å·",
            "advice": "æ²¹æ°”ETFå…³æ³¨ä¾›ç»™ç«¯å˜åŒ–",
        },
    },
]


def _ensure_commodity_events(events, now):
    """ç¡®ä¿å¤§å®—å•†å“æ ¸å¿ƒæ¿å—å§‹ç»ˆæœ‰äº‹ä»¶è¦†ç›– (LLMå¯èƒ½é—æ¼)"""
    all_sectors = set()
    for e in events:
        all_sectors.update(e.get('sectors_positive', []))
        all_sectors.update(e.get('sectors_negative', []))

    added = 0
    for fb in _COMMODITY_FALLBACKS:
        if not fb['key_sectors'] & all_sectors:
            # è¯¥æ¿å—æœªè¢«ä»»ä½•åŠ¨æ€äº‹ä»¶è¦†ç›– â†’ æ³¨å…¥å¸¸é©»äº‹ä»¶
            idx = len(events)
            evt = dict(fb['template'])
            evt['id'] = f"evt_{now.strftime('%Y%m%d')}_base_{idx+1:03d}"
            evt['confidence'] = 0.6
            evt['source'] = "å¸¸é©»åŸºç¡€äº‹ä»¶"
            evt['time'] = now.isoformat()
            events.append(evt)
            added += 1
            print(f"  ğŸ“Œ è¡¥å……å¸¸é©»äº‹ä»¶: {evt['title']} (åŠ¨æ€äº‹ä»¶æœªè¦†ç›– {fb['key_sectors']})")

    if added:
        print(f"  å…±è¡¥å…… {added} ä¸ªå¤§å®—å•†å“å¸¸é©»äº‹ä»¶")
    return events


def build_output(llm_result, prev_data, now):
    """ç»„è£…æœ€ç»ˆJSONè¾“å‡º"""
    events = []
    for i, e in enumerate(llm_result.get('events', [])[:12]):
        events.append(enrich_event(e, i, now))

    # === è¡¥å……å¤§å®—å•†å“å¸¸é©»äº‹ä»¶ (ç¡®ä¿æ²¹æ°”/æœ‰è‰²/é»„é‡‘æŒä»“å§‹ç»ˆå¯è¢«å½’å› ) ===
    events = _ensure_commodity_events(events, now)

    # çƒ­åº¦å›¾: è¡¥å……è¶‹åŠ¿
    heatmap = []
    for h in llm_result.get('heatmap', []):
        tag = h.get('tag', '')
        if tag not in MARKET_TAGS:
            continue
        temp = max(0, min(100, h.get('temperature', 50)))
        heatmap.append({
            "tag": tag,
            "temperature": temp,
            "sentiment": round(h.get('sentiment', 0), 2),
            "trend": compute_trend(temp, prev_data, tag),
        })
    # ç¡®ä¿æ‰€æœ‰æ ‡ç­¾éƒ½æœ‰çƒ­åº¦æ•°æ®
    existing_tags = {h['tag'] for h in heatmap}
    for tag in MARKET_TAGS:
        if tag not in existing_tags:
            heatmap.append({"tag": tag, "temperature": 50, "sentiment": 0, "trend": "stable"})
    heatmap.sort(key=lambda x: x['temperature'], reverse=True)

    # å¸‚åœºæ€»è§ˆåˆ†æ•°
    if events:
        avg_sentiment = sum(e['sentiment'] * abs(e['impact']) for e in events) / max(sum(abs(e['impact']) for e in events), 1)
        outlook_score = int(50 + avg_sentiment * 25)
    else:
        outlook_score = 50
    outlook_score = max(10, min(90, outlook_score))

    return {
        "updated_at": now.isoformat(),
        "heatmap": heatmap,
        "events": events,
        "outlook": {
            "period": f"{now.year}å¹´{now.month}æœˆ",
            "summary": llm_result.get('outlook_summary', 'å¸‚åœºç»“æ„æ€§è¡Œæƒ…å»¶ç»­'),
            "score": outlook_score,
        },
        "meta": {
            "news_count": 0,  # filled by main
            "sources": [],
            "model": MODEL,
        }
    }


# ==================== ä¸»æµç¨‹ ====================

def main():
    now = datetime.now(timezone(timedelta(hours=8)))
    print(f"{'='*50}")
    print(f"åŸºé‡‘åŠ©æ‰‹ - å®è§‚äº‹ä»¶è¿½è¸ªç®¡é“")
    print(f"æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')} CST")
    print(f"æ¨¡å‹: {MODEL}")
    print(f"{'='*50}")

    # 1. å¤šæºæŠ“å–æ–°é—»
    print("\nğŸ“¡ [1/3] æŠ“å–è´¢ç»æ–°é—»...")
    all_news = []
    sources_ok = []

    for name, fetcher in [
        ('æ–°æµªè´¢ç»', fetch_sina_news),
        ('ä¸œæ–¹è´¢å¯Œ', fetch_eastmoney_news),
        ('è´¢è”ç¤¾', fetch_cls_news),
        ('BBC', fetch_rss_bbc),
    ]:
        try:
            items = fetcher()
            if items:
                all_news.extend(items)
                sources_ok.append(name)
                print(f"  âœ… {name}: {len(items)} æ¡")
            else:
                print(f"  âš ï¸ {name}: 0 æ¡")
        except Exception as e:
            print(f"  âŒ {name}: {e}")

    if not all_news:
        print("\nâŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ–°é—», ä¿ç•™ä¸Šæ¬¡æ•°æ®")
        sys.exit(0)

    # å»é‡
    seen = set()
    deduped = []
    for n in all_news:
        key = re.sub(r'\W', '', n['title'])[:30]
        if key not in seen:
            seen.add(key)
            deduped.append(n)
    print(f"\n  æ€»è®¡: {len(all_news)} æ¡, å»é‡å: {len(deduped)} æ¡")

    # 2. LLM ç»“æ„åŒ–
    print("\nğŸ§  [2/3] AIç»“æ„åŒ–æå–...")
    llm_result = call_llm(deduped)

    if not llm_result:
        print("\nâŒ LLMåˆ†æå¤±è´¥, ä¿ç•™ä¸Šæ¬¡æ•°æ®")
        sys.exit(0)

    print(f"  æå–äº‹ä»¶: {len(llm_result.get('events', []))} æ¡")
    print(f"  çƒ­åº¦æ ‡ç­¾: {len(llm_result.get('heatmap', []))} ä¸ª")

    # 3. ç»„è£…è¾“å‡º
    print("\nğŸ“¦ [3/3] ç»„è£…è¾“å‡º...")
    prev_data = load_previous()
    output = build_output(llm_result, prev_data, now)
    output['meta']['news_count'] = len(deduped)
    output['meta']['sources'] = sources_ok

    # å†™å…¥æ–‡ä»¶
    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\n{'='*50}")
    print(f"âœ… è¾“å‡º: {OUTPUT_PATH}")
    print(f"   äº‹ä»¶: {len(output['events'])} æ¡")
    print(f"   çƒ­åº¦: {len(output['heatmap'])} æ ‡ç­¾")
    print(f"   æ€»è§ˆ: {output['outlook']['summary']}")
    print(f"   åˆ†æ•°: {output['outlook']['score']}")
    print(f"{'='*50}")


if __name__ == '__main__':
    main()
