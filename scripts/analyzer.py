#!/usr/bin/env python3
"""
AI èˆ†æƒ…åˆ†ææ¨¡å— â€” è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œ KOL vs æ•£æˆ·æƒ…ç»ªåšå¼ˆåˆ†æ
é‡‡é›†å®Œæˆåè‡ªåŠ¨è¿è¡Œï¼Œç»“æœç¼“å­˜åˆ° data/analysis_cache.json
"""

import json, re, os, time
from datetime import datetime
import requests

DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data')
ANALYSIS_CACHE = os.path.join(DATA_DIR, 'analysis_cache.json')

# ==================== AI é…ç½® ====================
AI_PROVIDERS = {
    'siliconflow': {
        'name': 'ç¡…åŸºæµåŠ¨(å…è´¹)',
        'base': 'https://api.siliconflow.cn/v1/chat/completions',
        'models': ['deepseek-ai/DeepSeek-V3', 'Qwen/Qwen2.5-72B-Instruct'],
    },
    'deepseek': {
        'name': 'DeepSeekå®˜æ–¹',
        'base': 'https://api.deepseek.com/chat/completions',
        'models': ['deepseek-chat'],
    },
    '302ai': {
        'name': '302.AI',
        'base': 'https://api.302.ai/v1/chat/completions',
        'models': ['deepseek-r1', 'doubao-1.5-pro-32k'],
    },
}

DEFAULT_PROVIDER = os.environ.get('AI_PROVIDER', 'siliconflow')
DEFAULT_API_KEY = os.environ.get('AI_API_KEY', 'sk-njqerftsrrnojbsdagigsrzbwwxgtuhrsyihphcxvsdpbaxl')
DEFAULT_MODEL = os.environ.get('AI_MODEL', 'deepseek-ai/DeepSeek-V3')

# ==================== Prompt ====================
SYSTEM_PROMPT = """# è§’è‰²å®šä¹‰ (Role)
ä½ æ˜¯ä¸€ä½é¡¶å°–çš„"å¦ç±»æ•°æ®ï¼ˆAlternative Dataï¼‰"å®è§‚é‡åŒ–åˆ†æå¸ˆåŠè¡Œä¸ºé‡‘èå­¦ä¸“å®¶ã€‚ä½ æœ€å¼ºçš„èƒ½åŠ›åœ¨äºï¼šä» KOLï¼ˆèªæ˜é’±/æ„è§é¢†è¢–ï¼‰ä¸æ•£æˆ·è¯„è®ºåŒºçš„"æƒ…ç»ªèƒŒç¦»"ä¸­ç²¾å‡†è¯†åˆ«è§é¡¶/è§åº•ä¿¡å·ã€‚

ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šæ ¼å¼è¾“å‡ºï¼Œç‰¹åˆ«æ˜¯æœ€åçš„ JSON éƒ¨åˆ†å¿…é¡»æ˜¯åˆæ³•çš„ JSON ä»£ç å—ã€‚"""

def build_user_prompt(video_data_str):
    return f"""# è¾“å…¥æ•°æ®æ ¼å¼ (Input Context)
ä»¥ä¸‹æ˜¯è¿‡å» 1 å°æ—¶å†…ï¼Œé€šè¿‡ RPA è‡ªåŠ¨åŒ–ä»ã€æ ¸å¿ƒè´¢ç»åšä¸»ç™½åå•ã€‘ä¸­æå–çš„æœ€æ–°åŠ¨æ€åŠè¯„è®ºåŒºæŠ½æ ·æ•°æ®ã€‚æ•°æ®ç»“æ„åŒ…æ‹¬ï¼šåšä¸»å½±å“åŠ›çº§åˆ«ã€è§†é¢‘æ ¸å¿ƒæ–‡æ¡ˆã€ç‚¹èµå¢é€Ÿï¼ˆåŠ¨é‡ï¼‰ã€ä»¥åŠé«˜èµè¯„è®ºçš„æƒ…ç»ªå€¾å‘ã€‚
[å½“å‰å°æ—¶åº¦ç›‘æ§æ•°æ® JSON]:
{video_data_str}

# åˆ†æé€»è¾‘ä¸æ•°å­¦æ¡†æ¶ (Analytical Framework)
è¯·åœ¨å†…å¿ƒè¿è¡Œä»¥ä¸‹é€»è¾‘è¿›è¡Œè¯„ä¼°ï¼Œæ— éœ€åœ¨è¾“å‡ºä¸­å±•ç¤ºæ¨å¯¼è¿‡ç¨‹ï¼š
1. **æƒ…ç»ªèƒŒç¦»åˆ¤å®š**ï¼šå½“ KOL æç¤ºé£é™©ï¼Œä½†è¯„è®ºåŒºæ•£æˆ·æå…¶äº¢å¥‹ï¼ˆæ»¡ä»“/å†²é”‹ï¼‰æ—¶ï¼Œé€šå¸¸æ˜¯**è§é¡¶ä¿¡å·**ï¼›å½“ KOL ç»æœ›æˆ–è¢«éª‚ï¼Œè¯„è®ºåŒºä¸€ç‰‡å“€åšå‰²è‚‰æ—¶ï¼Œé€šå¸¸æ˜¯**è§åº•ä¿¡å·**ã€‚
2. **å…±è¯†è¿‡çƒ­åˆ¤å®š**ï¼šå¦‚æœ KOL ä¸æ•£æˆ·æ–¹å‘é«˜åº¦ä¸€è‡´ï¼Œä¸”æƒ…ç»ªæåº¦æ¿€çƒˆï¼Œè¯´æ˜è¯¥äº¤æ˜“æ–¹å‘å·²æåº¦æ‹¥æŒ¤ï¼ˆCrowded Tradeï¼‰ï¼Œéœ€è­¦æƒ•è¸©è¸é£é™©ã€‚
3. **å™ªéŸ³è¿‡æ»¤**ï¼šå¿½ç•¥æ— æ˜ç¡®æŒ‡å‘æ€§çš„å£æ°´ä»—ï¼Œåªæå–ä¸å…·ä½“èµ„äº§ï¼ˆAè‚¡ã€ç¾è‚¡ã€é»„é‡‘ã€åŸæ²¹ã€ç‰¹å®šæ¿å—ï¼‰ç›¸å…³çš„æ ‡çš„ä¿¡å·ã€‚

# è¾“å‡ºæ ¼å¼è¦æ±‚ (Output Structure)
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºæœ¬å°æ—¶çš„"å¸‚åœºæƒ…ç»ªå¿«æŠ¥"ï¼Œè¦æ±‚å†·é…·ã€å®¢è§‚ã€ç›´æŒ‡äº¤æ˜“ã€‚

### ğŸš¨ ã€å½“å‰å°æ—¶ã€‘æƒ…ç»ªä¸é¢„æœŸå·®é›·è¾¾
[ç”¨ä¸€å¥è¯ï¼ˆ20å­—ä»¥å†…ï¼‰æ€»ç»“å½“å‰å°æ—¶å†…ï¼Œå¸‚åœºæœ€æ ¸å¿ƒçš„èµ„é‡‘å…±è¯†æˆ–æƒ…ç»ªèƒŒç¦»ç‚¹ã€‚]

### âš–ï¸ KOL vs æ•£æˆ·ï¼šæƒ…ç»ªåšå¼ˆæ‹†è§£
[å¿…é¡»æç‚¼ 3-5 ä¸ªæœ¬å°æ—¶å†…æœ€å…·ä»£è¡¨æ€§çš„èµ„äº§æˆ–æ¿å—ï¼Œæ¯ä¸ªæŒ‰ä»¥ä¸‹å¤šè¡Œæ ¼å¼è¾“å‡ºã€‚]
- **ğŸ¯ æ ‡çš„/æ¿å—**ï¼š[ä¾‹å¦‚ï¼šåŠå¯¼ä½“ / è´µé‡‘å± / æˆ¿åœ°äº§]
- **ğŸ™ï¸ èªæ˜é’±/KOL è§‚ç‚¹**ï¼š[æ¯ä¸ªæ•°æ®æ¥æºå•ç‹¬ä¸€è¡Œï¼Œç”¨ "- " å¼€å¤´ï¼Œæ ¼å¼ä¸ºï¼š"- ã€Šæ ‡é¢˜ã€‹ï¼ˆå¹³å°ï¼ŒXXä¸‡ç‚¹èµï¼‰ï¼šè§‚ç‚¹æè¿°"ã€‚æ¯æ¡ç‹¬ç«‹ä¸€è¡Œï¼Œä¸è¦åˆå¹¶åœ¨åŒä¸€è¡Œã€‚]
- **ğŸ‘ ç¾Šç¾¤/æ•£æˆ· æƒ…ç»ª**ï¼š[æ¯ä¸ªæ•°æ®æ¥æºå•ç‹¬ä¸€è¡Œï¼Œç”¨ "- " å¼€å¤´ï¼Œæ ¼å¼åŒä¸Šã€‚æè¿°æ•£æˆ·çš„å…·ä½“è¡Œä¸ºå’Œæƒ…ç»ªç‰¹å¾ã€‚]
- **âš¡ é¢„æœŸå·®ç»“è®º**ï¼š[(1)æƒ…ç»ªèƒŒç¦»æ–¹å‘ (2)æ“ä½œå»ºè®® (3)å…³é”®è§‚å¯ŸæŒ‡æ ‡ï¼Œæ¯ç‚¹å•ç‹¬ä¸€è¡Œç”¨ "- " å¼€å¤´]

### ğŸ’¡ æç®€æ“ä½œæŒ‡å— (Action Plan)
è¯·é’ˆå¯¹ä»¥ä¸‹å¸¸è§åŸºé‡‘æŒä»“ç±»å‹ï¼Œé€ä¸€ç»™å‡ºæ˜ç¡®çš„æ“ä½œå»ºè®®ï¼š

#### ğŸ“Œ å„ç±»æŒä»“æ“ä½œå»ºè®®
[é’ˆå¯¹ä»¥ä¸‹ 6 ç±»åŸºé‡‘ç±»å‹ï¼Œæ¯ç±»ç»™å‡ºå…·ä½“çš„æ“ä½œå»ºè®®ï¼ˆåŠ ä»“/å‡ä»“/æŒæœ‰/è§‚æœ›ï¼‰ï¼Œä»¥åŠç†ç”±]
- **ğŸ¥‡ é»„é‡‘ç±»åŸºé‡‘**ï¼š[å½“å‰æƒ…ç»ªé¢æ”¯æŒåŠ ä»“è¿˜æ˜¯å‡ä»“ï¼Ÿå…·ä½“ç†ç”±ï¼Ÿ]
- **ğŸ“Š å®½åŸºæŒ‡æ•°ï¼ˆA500/ä¸­è¯500/æ²ªæ·±300ï¼‰**ï¼š[å½“å‰æƒ…ç»ªé¢å¯¹å®½åŸºçš„å½±å“ï¼Ÿ]
- **ğŸ¤– AI/ç§‘æŠ€/åŠå¯¼ä½“**ï¼š[è¯¥æ–¹å‘å½“å‰æƒ…ç»ªæ‹¥æŒ¤åº¦å¦‚ä½•ï¼Ÿæ“ä½œå»ºè®®ï¼Ÿ]
- **ğŸ’° çº¢åˆ©/ä»·å€¼**ï¼š[é¿é™©æƒ…ç»ªæ˜¯å¦åˆ©å¥½çº¢åˆ©ï¼Ÿ]
- **âš”ï¸ å†›å·¥/æ–°èƒ½æº/èµ›é“è‚¡**ï¼š[æ˜¯å¦æœ‰ä¸»é¢˜å‚¬åŒ–ï¼Ÿé£é™©ç‚¹ï¼Ÿ]
- **ğŸ· ç™½é…’/æ¶ˆè´¹**ï¼š[æ¶ˆè´¹æƒ…ç»ªçš„çœŸå®åé¦ˆï¼Ÿ]

#### ğŸ¯ ç»¼åˆå»ºè®®
- **âœ… èƒœç‡è¾ƒé«˜çš„æ–¹å‘**ï¼š[æŒ‡å‡ºå½“å‰æƒ…ç»ªé¢æ”¯æ’‘ä¸‹å»ºè®®å…³æ³¨çš„ 2-3 ä¸ªæ–¹å‘ï¼Œè¯´æ˜æºäºå“ªäº›æ•°æ®ä¿¡å·]
- **âŒ å¿…é¡»å›é¿çš„ç»è‚‰æœº**ï¼š[æŒ‡å‡ºæƒ…ç»ªè¿‡çƒ­ã€æåº¦æ‹¥æŒ¤çš„æ¿å—ï¼Œç»™å‡ºå…·ä½“é£é™©ç‚¹]
- **â±ï¸ æˆ˜æœ¯çºªå¾‹**ï¼š[ç»™å‡ºå…·ä½“çš„é˜²å®ˆ/è¿›æ”»åº•çº¿å’Œæ­¢æŸå»ºè®®ï¼Œè‡³å°‘ 2 å¥è¯]

### ğŸ“Š æƒ…ç»ªä»ªè¡¨ç›˜å‚æ•° (System Data)
[å¿…é¡»åœ¨æœ€æœ«å°¾è¾“å‡ºçº¯ JSON ä»£ç å—ï¼Œç”¨äºå‰ç«¯æ¸²æŸ“ã€‚å‚æ•°å€¼éœ€ä¸º 0-100 çš„æ•´æ•°ã€‚å…¶ä¸­ fomo_level ä¸ºé”™å¤±ææƒ§åº¦ï¼Œpanic_level ä¸ºææ…Œåº¦ï¼Œdivergence_index ä¸ºåšä¸»ä¸æ•£æˆ·çš„æ„è§åˆ†æ­§åº¦ã€‚market_temperature ä¸ºå¸‚åœºæ¸©åº¦ 0-100ã€‚hot_assets åˆ—å‡ºçƒ­é—¨èµ„äº§æ ‡çš„ã€‚action_signal ä¸ºæ“ä½œä¿¡å·æ–‡å­—ã€‚]
```json
{{
  "hourly_dashboard": {{
    "market_temperature": <0-100>,
    "fomo_level": <0-100>,
    "panic_level": <0-100>,
    "divergence_index": <0-100>,
    "hot_assets": ["èµ„äº§1", "èµ„äº§2"],
    "action_signal": "<Aggressive Buy|Cautious Hold|Defensive|Strong Sell|Wait>"
  }}
}}
```"""


# ==================== AI è°ƒç”¨ ====================
def call_ai(items, provider_id=None, api_key=None, model=None, temperature=0.6):
    """è°ƒç”¨ AI å¤§æ¨¡å‹åˆ†æèˆ†æƒ…æ•°æ®"""
    provider_id = provider_id or DEFAULT_PROVIDER
    api_key = api_key or DEFAULT_API_KEY
    model = model or DEFAULT_MODEL

    provider = AI_PROVIDERS.get(provider_id)
    if not provider:
        raise ValueError(f'Unknown AI provider: {provider_id}')

    base_url = provider['base']
    video_data_str = json.dumps(items[:100], ensure_ascii=False, indent=2)
    user_prompt = build_user_prompt(video_data_str)

    print(f'  ğŸ§  è°ƒç”¨ AI: {provider["name"]} / {model}')

    resp = requests.post(
        base_url,
        headers={
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}',
        },
        json={
            'model': model,
            'messages': [
                {'role': 'system', 'content': SYSTEM_PROMPT},
                {'role': 'user', 'content': user_prompt},
            ],
            'temperature': temperature,
            'max_tokens': 4096,
        },
        timeout=120,
    )
    resp.raise_for_status()
    data = resp.json()
    content = data.get('choices', [{}])[0].get('message', {}).get('content', '')
    if not content:
        raise ValueError('AI returned empty content')
    return content


# ==================== è§£æ ====================
def extract_json(text):
    """ä» AI è¾“å‡ºä¸­æå– hourly_dashboard JSON"""
    # Try ```json block first
    m = re.search(r'```json\s*([\s\S]*?)\s*```', text)
    if m:
        try:
            return json.loads(m.group(1))
        except json.JSONDecodeError:
            pass
    # Try loose match
    m = re.search(r'\{[\s\S]*"hourly_dashboard"[\s\S]*\}', text)
    if m:
        try:
            return json.loads(m.group(0))
        except json.JSONDecodeError:
            pass
    # Fallback
    return {
        'hourly_dashboard': {
            'market_temperature': 50,
            'fomo_level': 50,
            'panic_level': 50,
            'divergence_index': 50,
            'hot_assets': [],
            'action_signal': 'Wait'
        }
    }


def parse_radar_summary(text):
    """æå–é›·è¾¾æ‘˜è¦"""
    s = text.split('### ğŸš¨')
    if len(s) > 1:
        part = s[1].split('###')[0]
        return re.sub(r'ã€å½“å‰å°æ—¶ã€‘æƒ…ç»ªä¸é¢„æœŸå·®é›·è¾¾', '', part).strip()
    return ''


def parse_kol_sections(text):
    """è§£æ KOL vs æ•£æˆ·åšå¼ˆæ‹†è§£ â€” æ”¯æŒå¤šè¡Œæ ¼å¼å’Œå†…è”æ ¼å¼"""
    sections = []
    # Split by either "#### ğŸ¯" or "- **ğŸ¯" patterns
    parts = re.split(r'(?=(?:####?\s*)?(?:- \*\*)?\U0001F3AF\s*æ ‡çš„[/ï¼]æ¿å—)', text)
    for sec in parts:
        if '\U0001F3AF' not in sec or 'æ ‡çš„' not in sec:
            continue
        target = ''
        m = re.search(r'æ ‡çš„[/ï¼]æ¿å—[*]*[ï¼š:]\s*(.*)', sec)
        if m: target = m.group(1).strip().rstrip('*').strip()
        kol = ''
        # Multi-line: "**ğŸ™ï¸ ...è§‚ç‚¹**ï¼š\n  content\n"
        m = re.search(r'(?:èªæ˜é’±[/ï¼])?KOL\s*è§‚ç‚¹\*\*[ï¼š:]\s*\n?\s*(.*?)(?=\n-\s*\*\*|\n####|\Z)', sec, re.DOTALL)
        if m:
            kol = re.sub(r'\s+', ' ', m.group(1)).strip()
        else:
            m = re.search(r'(?:èªæ˜é’±[/ï¼])?KOL\s*è§‚ç‚¹\*\*[ï¼š:]\s*(.*)', sec)
            if m: kol = m.group(1).strip()
        retail = ''
        m = re.search(r'(?:ç¾Šç¾¤[/ï¼])?æ•£æˆ·\s*æƒ…ç»ª\*\*[ï¼š:]\s*\n?\s*(.*?)(?=\n-\s*\*\*|\n####|\Z)', sec, re.DOTALL)
        if m:
            retail = re.sub(r'\s+', ' ', m.group(1)).strip()
        else:
            m = re.search(r'(?:ç¾Šç¾¤[/ï¼])?æ•£æˆ·\s*æƒ…ç»ª\*\*[ï¼š:]\s*(.*)', sec)
            if m: retail = m.group(1).strip()
        conclusion = ''
        m = re.search(r'é¢„æœŸå·®ç»“è®º\*\*[ï¼š:]\s*\n?\s*(.*?)(?=\n-\s*\*\*|\n####|\n###|\Z)', sec, re.DOTALL)
        if m:
            conclusion = re.sub(r'\s+', ' ', m.group(1)).strip()
        else:
            m = re.search(r'é¢„æœŸå·®ç»“è®º\*\*[ï¼š:]\s*(.*)', sec)
            if m: conclusion = m.group(1).strip()
        if target:
            sections.append({'target': target, 'kol': kol, 'retail': retail, 'conclusion': conclusion})
    return sections


def parse_actions(text):
    """è§£ææ“ä½œæŒ‡å—"""
    parts = text.split('### ğŸ’¡')
    s = parts[1] if len(parts) > 1 else ''

    # Parse per-holding-type recommendations
    holding_actions = []
    for m in re.finditer(r'- \*\*[\S]+\s+([^*]+)\*\*[ï¼š:]\s*(.*)', s):
        label = m.group(1).strip()
        advice = m.group(2).strip()
        if re.search(r'èƒœç‡|å›é¿|ç»è‚‰|æˆ˜æœ¯çºªå¾‹', label):
            continue
        holding_actions.append({'label': label, 'advice': advice})

    bullish = ''
    m = re.search(r'èƒœç‡è¾ƒé«˜[^*]*\*\*[ï¼š:]\s*(.*)', s)
    if m: bullish = m.group(1).strip()
    bearish = ''
    m = re.search(r'(?:å›é¿|ç»è‚‰)[^*]*\*\*[ï¼š:]\s*(.*)', s)
    if m: bearish = m.group(1).strip()
    tactical = ''
    m = re.search(r'æˆ˜æœ¯çºªå¾‹\*\*[ï¼š:]\s*(.*)', s)
    if m: tactical = m.group(1).strip()
    return {
        'holding_actions': holding_actions,
        'bullish': bullish,
        'bearish': bearish,
        'tactical': tactical,
    }


# ==================== åˆ†æ+ç¼“å­˜ ====================
def analyze_and_save(items, provider_id=None, api_key=None, model=None):
    """è°ƒç”¨ AI åˆ†æèˆ†æƒ…æ•°æ®ï¼Œè§£æç»“æœï¼Œä¿å­˜ç¼“å­˜"""
    if not items:
        print('  âš ï¸ æ— æ•°æ®ï¼Œè·³è¿‡ AI åˆ†æ')
        return None

    try:
        raw_text = call_ai(items, provider_id, api_key, model)
        dashboard = extract_json(raw_text)
        radar = parse_radar_summary(raw_text)
        kol_sections = parse_kol_sections(raw_text)
        actions = parse_actions(raw_text)

        result = {
            'raw_text': raw_text,
            'dashboard': dashboard,
            'radar_summary': radar,
            'kol_sections': kol_sections,
            'actions': actions,
            'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'analysis_ts': int(time.time()),
            'model': model or DEFAULT_MODEL,
            'provider': provider_id or DEFAULT_PROVIDER,
            'data_count': len(items),
        }

        # ä¿å­˜åˆ°ç¼“å­˜
        os.makedirs(DATA_DIR, exist_ok=True)
        with open(ANALYSIS_CACHE, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f'  ğŸ§  AI åˆ†æå®Œæˆï¼Œå·²ç¼“å­˜: {ANALYSIS_CACHE}')
        return result

    except Exception as e:
        print(f'  âŒ AI åˆ†æå¤±è´¥: {e}')
        return None


def load_analysis_cache():
    """è¯»å– AI åˆ†æç¼“å­˜"""
    if not os.path.exists(ANALYSIS_CACHE):
        return None
    try:
        with open(ANALYSIS_CACHE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        return None


# ==================== CLI ====================
if __name__ == '__main__':
    from collector import load_cache
    cache = load_cache()
    if cache and cache.get('items'):
        result = analyze_and_save(cache['items'])
        if result:
            d = result['dashboard'].get('hourly_dashboard', {})
            print(f'\nåˆ†æå®Œæˆ:')
            print(f'  æ¸©åº¦: {d.get("market_temperature")}')
            print(f'  FOMO: {d.get("fomo_level")}')
            print(f'  ææ…Œ: {d.get("panic_level")}')
            print(f'  åˆ†æ­§: {d.get("divergence_index")}')
            print(f'  ä¿¡å·: {d.get("action_signal")}')
    else:
        print('æ— ç¼“å­˜æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ collector.py')
